{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Занятие 09\n",
    "# Обзор AutoML решений. Введение в тестирование гипотез\n",
    "\n",
    "This notebook is brought to you by Radoslav Neychev\n",
    "\n",
    "#### План занятия\n",
    "\n",
    "1. Разведочный анализ и предобработка данных\n",
    "2. Построение baseline решения\n",
    "3. Обзор AutoML решений:\n",
    "    * TPOT\n",
    "    * H2O AutoML\n",
    "    * Google AutoML\n",
    "4. Анализ ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: какой природы бывают данные?\n",
    "Данные следующей природы часто встречаются в прикладных задачах\n",
    "* __Табличные данные__. Классическая ситуация: на каждой строке отдельный объект, каждый столбец – некоторый признак, описывающий этот объект. Бывают мультикоррелирующие признаки. Информация кроется в значениях признаков. Перестановка признаков местами (перестановка столбцов) ни на что не влияет.\n",
    "\n",
    "* __Изображения__. Данные – изображения, состоящие из пикселей. Каждое изображение обладает пространственной структурой, информация кроется в том, как пиксели упорядочены. Перестановка пикселей приводит к потере информации.\n",
    "\n",
    "* __Последовательности__. Данные – наборы значений, на которых задано отношение порядка. Значения могут быть дискретными (например, ДНК), или же могут принимать значения из непрерывного интервала (временной ряд энергопотребления дата центра). Перестановка значений приводит к потере информации. Нельзя нарушать отношение порядка (тестирование на прошлом, обучение на будущем).\n",
    "\n",
    "* __Тексты__. Данные – наборы слов/символов. По факту являются последовательностями значений из конечного алфавита, но обладают достаточно строгой внутренней структурой ввиду существования грамматики.\n",
    "\n",
    "* __Графы__. Данные – набор вершин и связей между ними. Связь между парой вершин означает наличие некоторого отношения между этими вершинами, которое может быть как направленным, так и ненаправленным. Например, в социальной сети вершинами могут являться пользователи, пользователи находящиеся в списке друзей друг у друга связаны ребрами типа \"дружба\". Подписчики связаны с пользовтелем, на которого они подписаны направленным ребром типа \"подписка\".\n",
    "\n",
    "* __Данные сложной природы__. Например, видео – последовательность изображений; граф социальной сети, где для каждого пользователя доступны не только списки друзей и подписчиков, но и фотография/аватар, некоторые высказывания и пр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --user google-cloud-automl --force-reinstall --quiet\n",
    "! pip install --upgrade --user google-cloud-bigquery --force-reinstall --quiet\n",
    "! pip install --upgrade --user google-cloud-storage --force-reinstall --quiet\n",
    "! pip install --upgrade --user matplotlib --quiet\n",
    "! pip install --upgrade --user pandas --quiet\n",
    "! pip install --upgrade --user pandas-gbq --quiet\n",
    "! pip install --upgrade --user gcsfs --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tpot\n",
    "# ! pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "matplotlib.rcParams.update({\"font.size\": 15})\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "print(f\"Python version: {sys.version}\\n\")\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "\n",
    "sns.set(style=\"ticks\", context=\"talk\")\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import HTML\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark plots\n",
    "# plt.style.use('dark_background')\n",
    "# pio.templates.default = \"plotly_dark\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с данными\n",
    "Рассмотрим табличные данные о [поведении клиентов онлайн-магазина](https://www.kaggle.com/roshansharma/online-shoppers-intention) [1]. На основании информации о посетитиле необходимо предсказать, будет ли совершена покупка, т.е. решается задача бинарной классификации.\n",
    "\n",
    "Ответим на следующие вопросы:\n",
    "* Есть ли пропуски в данных?\n",
    "* Сбалансированны ли классы?\n",
    "* С какими типами данных предстоит работать?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. [Sakar, C.O., Polat, S.O., Katircioglu, M. et al. Neural Comput & Applic (2018)](https://link.springer.com/article/10.1007%2Fs00521-018-3523-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/datasets/online_shoppers_intention/online_shoppers_intention.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных небольших размеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некоторых наблюдениях есть пропуски, но их количество незначительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum() / len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исключим наблюдения с пропусками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в данных наблюдаются категориальные переменные. Перечислим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"OperatingSystems\",\n",
    "    \"Browser\",\n",
    "    \"Region\",\n",
    "    \"TrafficType\",\n",
    "    \"Month\",\n",
    "    \"VisitorType\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in categorical_features:\n",
    "    dataset[feature_name] = dataset[feature_name].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуальный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = dataset[\"Revenue\"].value_counts()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(class_counts.values, labels=class_counts.index, autopct=\"%.2f%%\")\n",
    "plt.title(\"Different classes\", fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит рассмотреть распределения значений признаков в зависимости от значения целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df1, df2, label1, label2, features):\n",
    "    \"\"\"\n",
    "    Code origin: https://www.kaggle.com/kageyama/lgbm-online-shopper-s-eda-and-classification\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(18, 22))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(3, 3, i)\n",
    "        sns.distplot(df1[feature], hist=True, label=label1)\n",
    "        sns.distplot(df2[feature], hist=True, label=label2)\n",
    "        plt.xlabel(feature, fontsize=14)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis=\"x\", which=\"major\", labelsize=12, pad=-6)\n",
    "        plt.tick_params(axis=\"y\", which=\"major\", labelsize=12)\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = dataset.loc[dataset[\"Revenue\"] == True]\n",
    "t1 = dataset.loc[dataset[\"Revenue\"] == False]\n",
    "features = dataset.columns.values[:9]\n",
    "plot_feature_distribution(t1, t0, \"False\", \"True\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature_name in categorical_features:\n",
    "    counts = dataset[feature_name].value_counts()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.pie(counts.values, labels=counts.index, autopct=\"%.2f%%\")\n",
    "    plt.legend()\n",
    "    plt.title(feature_name, fontsize=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df1, df2, label1, label2, features):\n",
    "    \"\"\"\n",
    "    Code origin: https://www.kaggle.com/kageyama/lgbm-online-shopper-s-eda-and-classification\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(18, 22))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(3, 3, i)\n",
    "        sns.distplot(df1[feature], hist=True, label=label1)\n",
    "        sns.distplot(df2[feature], hist=True, label=label2)\n",
    "        plt.xlabel(feature, fontsize=14)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis=\"x\", which=\"major\", labelsize=12, pad=-6)\n",
    "        plt.tick_params(axis=\"y\", which=\"major\", labelsize=12)\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "Некоторые модели умеют работать с категориальными признаками (напирмер, [CatBoost]()), но частый этап предобработки – кодирование категориальных признаков. Категориальная переменная может быть представлена как множество бинарных (индикатор каждого значения). Существуют и [другие методы](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder)  работы с категориальными признаками.\n",
    "\n",
    "Воспользуемся простым методом `.get_dummies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset[\"Revenue\"]\n",
    "feature_matrix = dataset.drop(columns=[\"Revenue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При разделении данных на обучающую и тестовую выборки стоит учесть дисбаланс классов. Для этого воспользуемся стратификацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_matrix, target, random_state=0, stratify=target.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение простого baseline-решения\n",
    "В качестве baseline-решения будет использоваться Random Forest Classifier c параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline (Random Forest with defauld hyperparameters) results:\\n\\n\")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Train balanced accuracy: {:0.5f}\".format(balanced_accuracy_score(y_train, rf.predict(X_train)))\n",
    ")\n",
    "print(\n",
    "    \"Test  balanced accuracy: {:0.5f}\".format(balanced_accuracy_score(y_test, rf.predict(X_test)))\n",
    ")\n",
    "print()\n",
    "print(\"Train ROC AUC: {:0.5f}\".format(roc_auc_score(y_train, rf.predict_proba(X_train)[:, 1])))\n",
    "print(\"Test  ROC AUC: {:0.5f}\".format(roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])))\n",
    "print()\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, rf.predict(X_test))\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 9)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "# classification report\n",
    "cr = classification_report(y_test, rf.predict(X_test), digits=5)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Судя по качеству на обучающей выборке, модель переобучилась. Также стоит учесть, что классы несбалансированны.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML\n",
    "### TPOT\n",
    "\n",
    "Данная библиотека упрощает _прототипирование_ , в том числе с помощью `sklearn`. Подробнее можно почитать [здесь [en]](https://epistasislab.github.io/tpot/), [здесь [en]](http://automl.info/tpot/) или [здесь [en]](https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9).\n",
    "Библиотека крайне проста в использовании. Одним из плюсов данной библиотеки является возможность импортировать не только лучшую обученную модель, но и программный код, который ее обучает.\n",
    "\n",
    "_Комментарий: Для использования AutoML на больших объемах данных необходимы серьезные вычислительные мощности._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create & fit TPOT classifier with\n",
    "tpot = TPOTClassifier(generations=10, population_size=10, verbosity=2, early_stop=2, n_jobs=10)\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для экспортирования программного для обучения лучшей модели необходимо указать имя файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our model code\n",
    "tpot.export(\"tpot_pipeline.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно провести визуальный анализ кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tpot_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения полученной модели с baseline (Random Forest) обратимся к использовавшимся ранее методам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TPOT AutoML results:\\n\\n\")\n",
    "print(\n",
    "    \"Train balanced accuracy: {:0.5f}\".format(\n",
    "        balanced_accuracy_score(y_train, tpot.predict(X_train))\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Test  balanced accuracy: {:0.5f}\".format(balanced_accuracy_score(y_test, tpot.predict(X_test)))\n",
    ")\n",
    "print()\n",
    "print(\"Train ROC AUC: {:0.5f}\".format(roc_auc_score(y_train, tpot.predict_proba(X_train)[:, 1])))\n",
    "print(\"Test  ROC AUC: {:0.5f}\".format(roc_auc_score(y_test, tpot.predict_proba(X_test)[:, 1])))\n",
    "print()\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, tpot.predict(X_test))\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 9)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "# classification report\n",
    "cr = classification_report(y_test, tpot.predict(X_test), digits=5)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Обратите внимание на небольшое повышение качества на тестовой выборке и снижения качества на обучающей выборке. \n",
    "Полученная модель меньше переобучена.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O\n",
    "Библиотека для AutoML от коллектива [H2O](https://www.h2o.ai) достаточно популярна в профессиональной среде (а также в соревнованиях по машинному обучению и анализу данных). Подробнее об `h2o.automl` можно почитать [здесь [ru]](https://neurohive.io/ru/tutorial/tutorial-po-primeneniju-automl-v-h2o-ai-dlya-avtomatizacii-podbora-giperparametrov-modeli/) или [здесь [en]](https://www.h2o.ai/products/h2o-automl/).\n",
    "\n",
    "_При работе на уже выделенной виртуальной машине на GCP опустим данный пункт (т.к. он требует ручной установки java на уже аллоцированной машине)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h2o\n",
    "# from h2o.automl import H2OAutoML\n",
    "\n",
    "# # initilaize an H20 instance running locally\n",
    "# h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2O требует некоторой предобработки данных в собственный формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert our data to h20Frame, an alternative to pandas datatables\n",
    "# train_feature_matrix = h2o.H2OFrame(X_train)\n",
    "# train_targets = h2o.H2OFrame(list(y_train))\n",
    "# train_data = train_feature_matrix.cbind(train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение моделей может занять серьезное время. Random seed зафиксирован для воспроизводимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run AutoML for 20 base models (limited to 1 hour max runtime by default)\n",
    "# aml = H2OAutoML(max_models=10, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aml.train(y=\"C1\", training_frame=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рейтинг топ-5 моделей доступен ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = aml.leaderboard\n",
    "# lb.head(rows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшую модель можно сохранить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2o.save_model(aml.leader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество модели на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = h2o.H2OFrame(X_test).cbind(h2o.H2OFrame(list(y_test)))\n",
    "# out_h2o_train = aml.predict(train_data).as_data_frame()\n",
    "# out_h2o_test = aml.predict(test_data).as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('H2O AutoML results:\\n\\n')\n",
    "\n",
    "\n",
    "# print('Train balanced accuracy: {:0.5f}'.format(balanced_accuracy_score(y_train, out_h2o_train['predict'])))\n",
    "# print('Test  balanced accuracy: {:0.5f}'.format(balanced_accuracy_score(y_test, out_h2o_test['predict'])))\n",
    "# print()\n",
    "# print('Train ROC AUC: {:0.5f}'.format(roc_auc_score(y_train, out_h2o_train['True'])))\n",
    "# print('Test  ROC AUC: {:0.5f}'.format(roc_auc_score(y_test, out_h2o_test['True'])))\n",
    "# print()\n",
    "\n",
    "\n",
    "# # confusion matrix\n",
    "# cm = confusion_matrix(y_test, out_h2o_test['predict'])\n",
    "# plt.rcParams['figure.figsize'] = (9, 9)\n",
    "# sns.heatmap(cm, annot=True)\n",
    "\n",
    "# # classification report\n",
    "# cr = classification_report(y_test, out_h2o_test['predict'], digits=5)\n",
    "# print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Полученные результаты превосходят baseline и сопоставимы с результатами TPOT (несколько им уступая).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google AutoML\n",
    "В отличие от рассмотренных решений, Google AutoML переносит вычисления на собственные вычислительные мощности. Для их использования необходимо активировать данную опцию в настройках Google Cloud Platform. Для активации, загрузки данных и получения доступов, обратитесь к [инструкции [ru]](https://docs.google.com/document/d/1hiGgIGtuisc1FbUZn31B59mkOcDP1YeMw3vyb4108Gg/edit?usp=sharing). В ноутбуке предполагается, что AutoML уже активирован и данные выгружены на GCP.\n",
    "\n",
    "Также вы можете обратиться к [официальной инструкции](https://cloud.google.com/vision/automl/object-detection/docs/quickstart-ui), где также рассматривается использование AutoML для обучения моделей без написания кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import automl_v1beta1 as automl\n",
    "from google.cloud import bigquery, storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"jovial-style-290414\"  # @param {type:\"string\"}\n",
    "COMPUTE_REGION = \"us-central1\"  # Currently only supported region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Комментарий: лучше переименовать загруженный ключ и убрать из имени пробелы._\n",
    "\n",
    "_Для запуска кода ниже на локальной машине необходимо установить `google-cloud-sdk`. Вы можете обратиться к [официальной инструкции](https://cloud.google.com/sdk/docs/install#deb). Не забудьте выбрать инструкцию для используемой системы (Windows/macOS/Debian/Ubuntu/...). Пожалуйста, внимательно прочитайте инструкцию. В случае возникновения ошибок может помочь [этот вопрос на StackOverflow](https://stackoverflow.com/questions/56679191/apt-get-is-broken-after-install-google-cloud-sdk-on-ubuntu-18-04-lts)._\n",
    "\n",
    "На машине, выделенной на GCP `google-cloud-sdk` уже установлен. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS MyFirstProject-c1fa9c397fbd.json\n",
    "! gcloud auth activate-service-account --key-file 'MyFirstProject-c1fa9c397fbd.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"netology_ai_course_practice/\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная строчка позволит проверить, что доступ к GCP и наборам данных налажен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -al gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DISPLAY_NAME = \"Netology_practice_3_dataset\"\n",
    "TARGET_COLUMN = \"Revenue\"\n",
    "\n",
    "\n",
    "MODEL_DISPLAY_NAME = \"automl_practice_model\"  # Model name\n",
    "TRAIN_BUDGET = 1000  # Maximum time to train model in milli-hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "tables_gcs_client = automl.GcsClient(client=storage_client)\n",
    "tables_client = automl.TablesClient(\n",
    "    project=PROJECT_ID, region=COMPUTE_REGION, gcs_client=tables_gcs_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target column\n",
    "tables_client.set_target_column(\n",
    "    dataset_display_name=DATASET_DISPLAY_NAME, column_spec_display_name=TARGET_COLUMN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let our model know that input columns may have missing values\n",
    "for col in tables_client.list_column_specs(\n",
    "    project=PROJECT_ID, dataset_display_name=DATASET_DISPLAY_NAME\n",
    "):\n",
    "    if TARGET_COLUMN in col.display_name:\n",
    "        continue\n",
    "    tables_client.update_column_spec(\n",
    "        project=PROJECT_ID,\n",
    "        dataset_display_name=DATASET_DISPLAY_NAME,\n",
    "        column_spec_display_name=col.display_name,\n",
    "        nullable=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее остается лишь запустить обучение. Выбор модели и настройка параметров будут происходит на стороне GCP, ядро данного ноутбука не будет задействовано."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start model training\n",
    "response = tables_client.create_model(\n",
    "    MODEL_DISPLAY_NAME,\n",
    "    dataset_display_name=DATASET_DISPLAY_NAME,\n",
    "    train_budget_milli_node_hours=TRAIN_BUDGET,\n",
    "    exclude_column_spec_names=[TARGET_COLUMN],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процесс обучения можно наблюдать во вкладке Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the model is trained, flag will be set True\n",
    "response.done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная процедура обучения займет некоторое время (порядка одного часа). Сейчас можно продолжить изучение ноутбука. Результаты можно будет проинтерпретировать в дальнейшем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы:\n",
    "* Методы AutoML позволяют значительно ускорить этап прототипирования, а в некоторых случаях добиться хороших результатов.\n",
    "* Для использования AutoML на реальных данных необходимы значительные вычислительные мощности.\n",
    "* Облачные провайдеры предоставляют для этого необходимые инструменты, но при использовании данных механизмов на постоянной основе стоит рассмотреть вопрос о переходе да собственные мощности.\n",
    "* Проверка гипотез и A/B тестирование – мощный инструмент при принятии решений.\n",
    "* При проведении тестирования стоит очень внимательно подходить к дизайну эксперимента.\n",
    "* При интерпретации результатов тестирования стоит обращать внимание на множество факторов (мощность критерия, значимость изменений с точки зрения бизнеса, сопутствующие риски и пр.), а не только на $p$-значение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-mipt]",
   "language": "python",
   "name": "conda-env-ml-mipt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
